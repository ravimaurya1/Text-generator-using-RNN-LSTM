{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text generator using LSTM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "l-6RZEMSGB7e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import Essential library"
      ]
    },
    {
      "metadata": {
        "id": "EutvmKdCD_B-",
        "colab_type": "code",
        "outputId": "99791d12-7133-430c-d262-7a67ae42842e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "tTf7iBsZGQyM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Connecting to Drive \n",
        "Because I am using colab.research.googe.com"
      ]
    },
    {
      "metadata": {
        "id": "oG77prtoGCAu",
        "colab_type": "code",
        "outputId": "634a4a6c-9726-4feb-cd43-d24b10a64af0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ny06sSzjGedM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Read File from Destination Path"
      ]
    },
    {
      "metadata": {
        "id": "Jlx4WpBDGK0C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filename ='/content/drive/My Drive/LSTM/dataset/ravi.txt'            #Change According to your path in your system.\n",
        "raw_text = open(filename).read()\n",
        "raw_text = raw_text.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nYXkCUs9Gl7K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Mapping every unique character present in file to number."
      ]
    },
    {
      "metadata": {
        "id": "9l3Zi9P5HQN8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c,i) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hZkW41KPG2fJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Dictionary of Mapping"
      ]
    },
    {
      "metadata": {
        "id": "ije5GcDDH2FM",
        "colab_type": "code",
        "outputId": "d0b681c0-7405-480d-ee72-4171d6d63920",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "print (char_to_int)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'\\n': 0, ' ': 1, '!': 2, '(': 3, ')': 4, '*': 5, ',': 6, '-': 7, '.': 8, ':': 9, ';': 10, '?': 11, '[': 12, ']': 13, '_': 14, 'a': 15, 'b': 16, 'c': 17, 'd': 18, 'e': 19, 'f': 20, 'g': 21, 'h': 22, 'i': 23, 'j': 24, 'k': 25, 'l': 26, 'm': 27, 'n': 28, 'o': 29, 'p': 30, 'q': 31, 'r': 32, 's': 33, 't': 34, 'u': 35, 'v': 36, 'w': 37, 'x': 38, 'y': 39, 'z': 40, '‘': 41, '’': 42, '“': 43, '”': 44, '\\ufeff': 45}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JNW4trUtG8I2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Analyzing Text file"
      ]
    },
    {
      "metadata": {
        "id": "MsCQxvEwH6LS",
        "colab_type": "code",
        "outputId": "8ee756d4-8471-4bde-b5c0-88efd21fa954",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print (\"Total Characters=\",n_chars)\n",
        "print (\"Total Vocab=\",n_vocab)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters= 144354\n",
            "Total Vocab= 46\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UdDOWELhHDoq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prepare the Dataset to train Our Model\n",
        "Here I choose the sequence length=100 i.e each character of sequence length is input for LSTM time\n",
        "step. This sequence act as input and output is 101th character of text."
      ]
    },
    {
      "metadata": {
        "id": "8tYptywBJ0Un",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "83cd4342-a5f7-4003-d42f-b1c93f0fa5be"
      },
      "cell_type": "code",
      "source": [
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length=100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0,n_chars-seq_length,1):\n",
        "  seq_in = raw_text[i:i + seq_length]\n",
        "  seq_out = raw_text[i+seq_length]\n",
        "  dataX.append([char_to_int[char] for char in seq_in])\n",
        "  dataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print (\"Total Patterns:\", n_patterns)   # Total Pattern means number of input example\n",
        "print (\"Number of example in input:\",len(dataX))\n",
        "print (\"Number of target:\",len(dataY))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Patterns: 144254\n",
            "Number of example in input: 144254\n",
            "Number of target: 144254\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jBEuZfoOJH3g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Lets take look of one training example\n",
        "Sequence is in integer."
      ]
    },
    {
      "metadata": {
        "id": "f2VykH8Tt8sa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f4fd5eb0-5e87-4c3f-ab9d-2046d4d170d6"
      },
      "cell_type": "code",
      "source": [
        "print (dataX[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[45, 17, 22, 15, 30, 34, 19, 32, 1, 23, 8, 1, 18, 29, 37, 28, 1, 34, 22, 19, 1, 32, 15, 16, 16, 23, 34, 7, 22, 29, 26, 19, 0, 0, 15, 26, 23, 17, 19, 1, 37, 15, 33, 1, 16, 19, 21, 23, 28, 28, 23, 28, 21, 1, 34, 29, 1, 21, 19, 34, 1, 36, 19, 32, 39, 1, 34, 23, 32, 19, 18, 1, 29, 20, 1, 33, 23, 34, 34, 23, 28, 21, 1, 16, 39, 1, 22, 19, 32, 1, 33, 23, 33, 34, 19, 32, 1, 29, 28, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "l_8tnc7jJa4H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now how data look in character."
      ]
    },
    {
      "metadata": {
        "id": "7VOqBp04veCy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "435f39a5-3269-49f6-b2a0-333126251676"
      },
      "cell_type": "code",
      "source": [
        "int_to_char =dict((i,c) for i,c in enumerate(chars))\n",
        "#this dataX[0] is in real\n",
        "s=[]\n",
        "print (\"\\\"\",''.join([int_to_char[value] for value in dataX[0]]),\"\\\"\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\" ﻿chapter i. down the rabbit-hole\n",
            "\n",
            "alice was beginning to get very tired of sitting by her sister on  \"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "H4AEVXL1J2wV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Now we have to reshape the Data\n",
        "1. Input data in [samples,time steps, features]<br>\n",
        "2.Normalize the input data\n",
        "3. One hot encode the output variable."
      ]
    },
    {
      "metadata": {
        "id": "F3Jhmac-wmPA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#reshape X to be [samples,time steps, features]\n",
        "X =np.reshape(dataX, (n_patterns, seq_length,1))      #Here feature is 1 becasue our every character is input to LSTM time step and each is represented by one integer.\n",
        "#normalize\n",
        "X=X/float(n_vocab)\n",
        "#one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T9eodb1ULEQb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Now its time to define our RNN model using LSMT cell."
      ]
    },
    {
      "metadata": {
        "id": "6Wgpm6xqxgCb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define the LSTM model\n",
        "model =Sequential()\n",
        "model.add(LSTM(256,input_shape=(X.shape[1],X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1],activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-5xDVg4ILRA9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train the model on Data."
      ]
    },
    {
      "metadata": {
        "id": "TU1X5u8Q6Ixd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1067
        },
        "outputId": "ac3a339e-bd39-430d-973b-25aac2c32fc5"
      },
      "cell_type": "code",
      "source": [
        "model.fit(X, y, epochs=20, batch_size=128)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/20\n",
            "144254/144254 [==============================] - 225s 2ms/step - loss: 3.0027\n",
            "Epoch 2/20\n",
            "144254/144254 [==============================] - 221s 2ms/step - loss: 2.7922\n",
            "Epoch 3/20\n",
            "144254/144254 [==============================] - 221s 2ms/step - loss: 2.6891\n",
            "Epoch 4/20\n",
            "144254/144254 [==============================] - 220s 2ms/step - loss: 2.6085\n",
            "Epoch 5/20\n",
            "144254/144254 [==============================] - 223s 2ms/step - loss: 2.5425\n",
            "Epoch 6/20\n",
            "144254/144254 [==============================] - 224s 2ms/step - loss: 2.4823\n",
            "Epoch 7/20\n",
            "  8576/144254 [>.............................] - ETA: 3:28 - loss: 2.4507"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-858afe7c1035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "h4wNuio-LWm5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Generate the text using above trained model."
      ]
    },
    {
      "metadata": {
        "id": "HVmBvOnp7ej-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "c473c039-2b60-439e-c477-bdc16b96b4b8"
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "# pick a random seed\n",
        "start =np.random.randint(0,len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print (\"Seed\")\n",
        "print (\"\\\"\",''.join([int_to_char[value] for value in pattern]),\"\\\"\")\n",
        "# generate characters\n",
        "for i in range(1000):\n",
        "  x = np.reshape(pattern,(1,len(pattern),1))\n",
        "  x = x/float(n_vocab)\n",
        "  prediction =model.predict(x,verbose=0)\n",
        "  index = np.argmax(prediction)\n",
        "  result = int_to_char[index]\n",
        "  seq_in = [int_to_char[value] for value in pattern]\n",
        "  sys.stdout.write(result)\n",
        "  pattern.append(index)\n",
        "  pattern = pattern[1:len(pattern)]\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed\n",
            "\" her was sitting on the ground near the\n",
            "door, staring stupidly up into the sky.\n",
            "\n",
            "alice went timidly u \"\n",
            "o the soiee  the woued to tee io the wooee  and the wooed to the soiee to the sooee  and the wooed to the sooee  an cel toe toeee to the sooee  and the wooed to the sooee  an cel toe toeee to the sooee  and the wooed to the sooee  an cel toe toeee to the sooee  and the wooed to the sooee  an cel toe toeee to the sooee  and the wooed to the sooee  an cel toe toeee to the sooee  and the wooed to the sooee  an cel toe toeee to the sooee  and the wooed to the sooee  an cel toe toeee to the sooee  and the wooed to the sooee  an cel toe toeee to the sooee  and the wooed to the sooee  an cel toe toeee to the sooee  and the wooed to the sooee  an cel toe toeee to the sooee  and the wooed to the sooee  an cel toe toeee to the sooee  and the wooed to the sooee  an cel toe toeee to the sooee  and the wooed to the sooee  an cel toe toeee to the sooee  and the wooed to the sooee  an cel toe toeee to the sooee  and the wooed to the sooee  an cel toe toeee to the sooee  and the wooed to the sooee  an"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vn-NNzafPBvt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Above sentence is repeating because it is trained on very shallow network and less number of epoch, for better result we have to trained model for large number of epochs."
      ]
    },
    {
      "metadata": {
        "id": "zVnDRkD1Asrk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}